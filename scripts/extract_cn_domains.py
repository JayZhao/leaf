import sys
import os
from pathlib import Path
from typing import List, Set, Tuple, Any, Counter
from google.protobuf.internal.decoder import _DecodeVarint32
from google.protobuf.internal.encoder import _EncodeVarint
import geosite_pb2
from publicsuffix2 import get_sld
import sys
from pathlib import Path

# å¸¸é‡å®šä¹‰
ADDITIONAL_DOMAINS = [
    'icloud.com',
    'apple-cloudkit.com',
    'wofhwifhafalffagy.com',
    'appstoreconnect.apple.com',
]

EXCLUDED_DOMAINS = {
    'googleapis.com',
    'gstatic.com',
    'amazon.com',
    'stackoverflow.com',
    'adobe.com',
}

# å¦‚æœé¡¶çº§åŸŸåéƒ¨åˆ†æ˜¯ä»£è¡¨å›½å®¶çš„,æ¯”å¦‚sg,tw,hkç­‰ç­‰,åˆ™è·³è¿‡, å› ä¸ºè¿™äº›åŸŸåé€šå¸¸æ˜¯å›½å¤–çš„, ä¸€æ—¦ä»£è¡¨å›½å®¶çš„æ—¶å€™åªæœ‰cnå¯ä»¥è¢«æ¥å—
EXCLUDED_COUNTRY_TLDS = {
    # äºšæ´²åœ°åŒº
    'hk',   # é¦™æ¸¯
    'tw',   # å°æ¹¾
    'sg',   # æ–°åŠ å¡
    'jp',   # æ—¥æœ¬
    'kr',   # éŸ©å›½
    'in',   # å°åº¦
    'th',   # æ³°å›½
    'vn',   # è¶Šå—
    'my',   # é©¬æ¥è¥¿äºš
    'id',   # å°åº¦å°¼è¥¿äºš
    
    # æ¬§æ´²åœ°åŒº
    'uk',   # è‹±å›½
    'de',   # å¾·å›½
    'fr',   # æ³•å›½
    'it',   # æ„å¤§åˆ©
    'es',   # è¥¿ç­ç‰™
    'nl',   # è·å…°
    'ru',   # ä¿„ç½—æ–¯
    
    # ç¾æ´²åœ°åŒº
    'us',   # ç¾å›½
    'ca',   # åŠ æ‹¿å¤§
    'mx',   # å¢¨è¥¿å“¥
    'br',   # å·´è¥¿
    
    # å¤§æ´‹æ´²
    'au',   # æ¾³å¤§åˆ©äºš
    'nz',   # æ–°è¥¿å…°
}

def format_size(size):
    """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°æ˜¾ç¤º"""
    for unit in ['B', 'KB', 'MB', 'GB']:
        if size < 1024.0:
            return f"{size:.2f} {unit}"
        size /= 1024.0
    return f"{size:.2f} TB"

def analyze_dat(file_path):
    """åˆ†ædatæ–‡ä»¶çš„å†…å®¹"""
    print(f"\nğŸ“– æ­£åœ¨åˆ†æ: {file_path}")
    print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {format_size(os.path.getsize(file_path))}")
    
    try:
        with open(file_path, 'rb') as f:
            data = f.read()
            site_group_list = geosite_pb2.SiteGroupList()
            site_group_list.ParseFromString(data)
            
        stats = {
            'groups': len(site_group_list.site_group),
            'domains': 0,
            'types': Counter(),
            'attributes': Counter(),
            'tags': []
        }
        
        for group in site_group_list.site_group:
            stats['tags'].append(group.tag)
            stats['domains'] += len(group.domain)
            
            for domain in group.domain:
                stats['types'][geosite_pb2.Domain.Type.Name(domain.type)] += 1
                for attr in domain.attribute:
                    if attr.HasField('bool_value'):
                        stats['attributes'][f"{attr.key}(bool)"] += 1
                    elif attr.HasField('int_value'):
                        stats['attributes'][f"{attr.key}(int)"] += 1
        
        return stats, site_group_list
        
    except Exception as e:
        print(f"âŒ æ–‡ä»¶åˆ†æé”™è¯¯: {e}")
        return None, None

def print_stats(stats):
    """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
    if not stats:
        return
        
    print("\nğŸ“Š æ–‡ä»¶ç»Ÿè®¡:")
    print(f"  â€¢ ç»„æ•°: {stats['groups']}")
    print(f"  â€¢ æ€»åŸŸåæ•°: {stats['domains']}")
    
    print("\n  â€¢ åŸŸåç±»å‹åˆ†å¸ƒ:")
    for type_name, count in stats['types'].most_common():
        print(f"    - {type_name}: {count} ({count/stats['domains']*100:.1f}%)")
    
    if stats['attributes']:
        print("\n  â€¢ å±æ€§åˆ†å¸ƒ:")
        for attr_name, count in stats['attributes'].most_common():
            print(f"    - {attr_name}: {count}")
    
    print("\n  â€¢ æ ‡ç­¾:")
    for tag in stats['tags']:
        print(f"    - {tag}")

def domain_to_u128(domain: str) -> int:
    """å°†åŸŸåè½¬æ¢ä¸ºu128æ ¼å¼
    1. å¦‚æœåŸŸåä»¥wwwå¼€å¤´ï¼Œåˆ™å»æ‰www
    2. ç§»é™¤æ‰€æœ‰éå­—æ¯æ•°å­—å­—ç¬¦
    3. å–æœ€å16ä¸ªå­—ç¬¦å¡«å……åˆ°u128ä¸­
    """
    # è·å–å¯æ³¨å†ŒåŸŸå
    registrable_domain = get_sld(domain)
    if not registrable_domain:
        registrable_domain = domain
        return None
    
    domain_bytes = bytes(registrable_domain, 'utf-8')
    
    # å–æœ€å16ä¸ªå­—èŠ‚
    domain_suffix = domain_bytes[-16:] if len(domain_bytes) > 16 else domain_bytes
    
    # åˆ›å»º16å­—èŠ‚æ•°ç»„
    bytes_array = bytearray(16)
    # ä»å·¦è¾¹å¼€å§‹å¡«å……
    bytes_array[:len(domain_suffix)] = domain_suffix
    
    result = int.from_bytes(bytes_array, byteorder='little', signed=False)
    
    return result

def extract_and_split_domains(input_file: str, binary_output: str):
    """æå–åŸŸåå¹¶åˆ†åˆ«å¤„ç†"""
    stats, site_group_list = analyze_dat(input_file)
    if not stats:
        raise Exception("æ–‡ä»¶åˆ†æå¤±è´¥")
    
    suffix_domains_u128 = []
    suffix_domains_original = []
    
    excluded_domains_u128 = {domain_to_u128(domain) for domain in EXCLUDED_DOMAINS}
    
    for site_group in site_group_list.site_group:
        if site_group.tag.lower() in {'cn', 'apple-cn'}:
            for domain in site_group.domain:
                if domain.type == 2:  # Domain type (suffix)
                    tld = domain.value.split('.')[-1].lower()
                    if tld in EXCLUDED_COUNTRY_TLDS:
                        continue
                        
                    u128_value = domain_to_u128(domain.value)
                    if u128_value not in excluded_domains_u128:
                        suffix_domains_u128.append(u128_value)
                        suffix_domains_original.append(domain.value)
    
    for domain in ADDITIONAL_DOMAINS:
        u128_value = domain_to_u128(domain)
        suffix_domains_u128.append(u128_value)
        suffix_domains_original.append(domain)
    
    txt_output = str(Path(binary_output).with_suffix('.txt'))
    with open(txt_output, 'w', encoding='utf-8') as f:
        f.write("# Suffix Domains\n")
        for domain in sorted(set(suffix_domains_original)):
            f.write(f"{domain}\n")
    
    suffix_domains_u128 = list(set(suffix_domains_u128))
    suffix_domains_u128.sort()
    
    with open(binary_output, 'wb') as f:
        for value in suffix_domains_u128:
            f.write(value.to_bytes(16, byteorder='little', signed=False))
    
    print(f"\nğŸ“Š åŸŸåç»Ÿè®¡:")
    print(f"  â€¢ å¤„ç†çš„åç¼€åŸŸåæ€»æ•°: {len(suffix_domains_u128)}")
    print(f"  â€¢ äºŒè¿›åˆ¶æ–‡ä»¶å¤§å°: {format_size(Path(binary_output).stat().st_size)}")
    print(f"  â€¢ åŸŸååˆ—è¡¨å·²ä¿å­˜è‡³: {txt_output}")

def main():
    script_dir = Path(__file__).parent
    parent_dir = script_dir.parent

    input_file = "site.dat"

    target_dirs = [
        parent_dir / "target/debug",
        parent_dir / "target/release"
    ]

    try:
        print("\nğŸš€ å¼€å§‹åŸŸåæå–å¤„ç†...")
        print(f"ğŸ“‚ è¾“å…¥æ–‡ä»¶: {input_file}")
        
        debug_dir = target_dirs[0]
        binary_output = debug_dir / "site_cn_binary.dat"
        
        print(f"ğŸ“‚ è¾“å‡ºæ–‡ä»¶å°†ä¿å­˜åˆ°: {debug_dir}")
        
        extract_and_split_domains(str(input_file), str(binary_output))
        
        release_dir = target_dirs[1]
        if release_dir.exists():
            print(f"\nğŸ“¦ æ­£åœ¨å¤åˆ¶æ–‡ä»¶åˆ° {release_dir}")
            import shutil
            
            shutil.copy2(binary_output, release_dir / binary_output.name)
            print(f"  âœ“ å·²å¤åˆ¶ {binary_output.name}")
            
            txt_output = binary_output.with_suffix('.txt')
            shutil.copy2(txt_output, release_dir / txt_output.name)
            print(f"  âœ“ å·²å¤åˆ¶ {txt_output.name}")
        
        print("\nâœ¨ å¤„ç†å®Œæˆï¼")
        
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()