# extract_cn_domains.py
import sys
import os
from google.protobuf.internal.decoder import _DecodeVarint32
from google.protobuf.internal.encoder import _EncodeVarint
import geosite_pb2
import time
from collections import Counter
import struct
from pathlib import Path

def format_size(size):
    """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°æ˜¾ç¤º"""
    for unit in ['B', 'KB', 'MB', 'GB']:
        if size < 1024.0:
            return f"{size:.2f} {unit}"
        size /= 1024.0
    return f"{size:.2f} TB"

def analyze_dat(file_path):
    """åˆ†ædatæ–‡ä»¶çš„å†…å®¹"""
    print(f"\nğŸ“– Analyzing: {file_path}")
    print(f"ğŸ“Š File size: {format_size(os.path.getsize(file_path))}")
    
    try:
        with open(file_path, 'rb') as f:
            data = f.read()
            site_group_list = geosite_pb2.SiteGroupList()
            site_group_list.ParseFromString(data)
            
        stats = {
            'groups': len(site_group_list.site_group),
            'domains': 0,
            'types': Counter(),
            'attributes': Counter(),
            'tags': []
        }
        
        for group in site_group_list.site_group:
            stats['tags'].append(group.tag)
            stats['domains'] += len(group.domain)
            
            for domain in group.domain:
                stats['types'][geosite_pb2.Domain.Type.Name(domain.type)] += 1
                for attr in domain.attribute:
                    if attr.HasField('bool_value'):
                        stats['attributes'][f"{attr.key}(bool)"] += 1
                    elif attr.HasField('int_value'):
                        stats['attributes'][f"{attr.key}(int)"] += 1
        
        return stats, site_group_list
        
    except Exception as e:
        print(f"âŒ Error analyzing file: {e}")
        return None, None

def print_stats(stats):
    """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
    if not stats:
        return
        
    print("\nğŸ“Š File Statistics:")
    print(f"  â€¢ Groups: {stats['groups']}")
    print(f"  â€¢ Total domains: {stats['domains']}")
    
    print("\n  â€¢ Domain types distribution:")
    for type_name, count in stats['types'].most_common():
        print(f"    - {type_name}: {count} ({count/stats['domains']*100:.1f}%)")
    
    if stats['attributes']:
        print("\n  â€¢ Attributes distribution:")
        for attr_name, count in stats['attributes'].most_common():
            print(f"    - {attr_name}: {count}")
    
    print("\n  â€¢ Tags:")
    for tag in stats['tags']:
        print(f"    - {tag}")

def domain_to_u128(domain: str) -> int:
    """å°†åŸŸåè½¬æ¢ä¸ºu128æ ¼å¼"""
    truncated = domain[-16:] if len(domain) > 16 else domain
    padded_domain = truncated.rjust(16, '\0')
    domain_bytes = padded_domain.encode('ascii')
    return int.from_bytes(domain_bytes, byteorder='little', signed=False)

def extract_and_split_domains(input_file: str, other_output: str, binary_output: str):
    """æå–åŸŸåå¹¶åˆ†åˆ«å¤„ç†"""
    stats, site_group_list = analyze_dat(input_file)
    if not stats:
        raise Exception("Failed to analyze input file")
    
    # å­˜å‚¨suffixç±»å‹çš„åŸŸåçš„u128å€¼å’ŒåŸå§‹åŸŸå
    suffix_domains_u128 = []
    suffix_domains_original = []  # å­˜å‚¨åŸå§‹åŸŸå
    regex_domains = []  # å­˜å‚¨regexç±»å‹çš„åŸŸå
    other_domains = []  # å­˜å‚¨å…¶ä»–ç±»å‹çš„åŸŸå
    
    # ç¡¬ç¼–ç è§„åˆ™ - éœ€è¦æ·»åŠ çš„åŸŸå
    additional_domains = [
        'icloud.com',
        'apple-cloudkit.com',
        'com.cn',
        'net.cn',
        'org.cn',
        'edu.cn',
        'gov.cn',
        'mil.cn',
        'ac.cn'
    ]
    
    # ç¡¬ç¼–ç è§„åˆ™ - éœ€è¦æ’é™¤çš„åŸŸå
    excluded_domains = {
        'googleapis.com',
        'gstatic.com',
        'amazon.com',
        'stackoverflow.com',
    }
    
    # åŸºç¡€çš„cnåŸŸåæ­£åˆ™è¡¨è¾¾å¼
    base_cn_regex = r"\.cn$"
    
    # ä»åŸå§‹æ•°æ®ä¸­æå–åŸŸå
    for site_group in site_group_list.site_group:
        if site_group.tag.lower() in {'cn', 'apple-cn'}:
            for domain in site_group.domain:
                if domain.type == 2:  # Domain type (suffix)
                    if domain.value not in excluded_domains:
                        u128_value = domain_to_u128(domain.value)
                        suffix_domains_u128.append(u128_value)
                        suffix_domains_original.append(domain.value)
                elif domain.type == 1:  # Regex type
                    regex_domains.append(domain.value)
                else:
                    other_domains.append((domain.type, domain.value, 
                        [(attr.key, attr.bool_value if attr.HasField('bool_value') 
                          else attr.int_value if attr.HasField('int_value') 
                          else None) for attr in domain.attribute]))
    
    # æ·»åŠ ç¡¬ç¼–ç çš„é¢å¤–åŸŸå
    for domain in additional_domains:
        u128_value = domain_to_u128(domain)
        suffix_domains_u128.append(u128_value)
        suffix_domains_original.append(domain)
    
    # æ·»åŠ åŸºç¡€cnæ­£åˆ™è¡¨è¾¾å¼
    regex_domains.append(base_cn_regex)
    
    # å°†æ‰€æœ‰regexç±»å‹çš„åŸŸåæ·»åŠ åˆ°other_domainsï¼ˆç”¨äºå†™å…¥datæ–‡ä»¶ï¼‰
    for regex in regex_domains:
        other_domains.append((1, regex, []))
    
    # å°†åŸå§‹åç¼€åŸŸåå’ŒregexåŸŸåä¿å­˜åˆ°æ–‡æœ¬æ–‡ä»¶
    txt_output = str(Path(binary_output).with_suffix('.txt'))
    with open(txt_output, 'w', encoding='utf-8') as f:
        # å†™å…¥åç¼€åŸŸå
        f.write("# Suffix Domains\n")
        for domain in sorted(suffix_domains_original):
            f.write(f"{domain}\n")
        
        # å†™å…¥regexåŸŸåï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        if regex_domains:
            f.write("\n# Regex Patterns\n")
            for pattern in sorted(regex_domains):
                f.write(f"{pattern}\n")
    
    # æ’åºu128æ•°ç»„
    suffix_domains_u128.sort()
    
    # æ‰“å°å‰10ä¸ªæ•°å­—
    print("\nğŸ“Š First 10 domain u128 values:")
    for i, value in enumerate(suffix_domains_u128[:10]):
        # å°†u128å€¼è½¬æ¢å›ASCIIå­—ç¬¦ä¸²
        bytes_value = value.to_bytes(16, byteorder='little', signed=False)
        ascii_str = bytes_value.decode('ascii').rstrip('\0')
        print(f"  [{i:2d}] {value} (hex: {hex(value)})")
        print(f"       ASCII: {ascii_str}")
    
    # å°†u128æ•°ç»„å†™å…¥äºŒè¿›åˆ¶æ–‡ä»¶ï¼ˆä½¿ç”¨little-endianï¼‰
    with open(binary_output, 'wb') as f:
        for value in suffix_domains_u128:
            f.write(value.to_bytes(16, byteorder='little', signed=False))
    
    # å°†å…¶ä»–ç±»å‹çš„åŸŸåå†™å…¥site_cn_other.dat
    write_other_domains(other_domains, other_output)
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“Š Domain Statistics:")
    print(f"  â€¢ Total suffix domains processed: {len(suffix_domains_u128)}")
    print(f"  â€¢ Total regex patterns: {len(regex_domains)}")  # æ–°å¢ï¼šæ˜¾ç¤ºregexæ•°é‡
    print(f"  â€¢ Total other domains: {len(other_domains)}")
    print(f"  â€¢ Binary file size: {format_size(Path(binary_output).stat().st_size)}")
    print(f"  â€¢ Other domains file size: {format_size(Path(other_output).stat().st_size)}")
    print(f"  â€¢ Domain list saved to: {txt_output}")

def write_other_domains(domains, output_file):
    """å°†å…¶ä»–ç±»å‹çš„åŸŸåå†™å…¥æ–‡ä»¶"""
    site_group_list = geosite_pb2.SiteGroupList()
    site_group = site_group_list.site_group.add()
    site_group.tag = "cn"
    
    for domain_type, domain_value, attributes in domains:
        domain = site_group.domain.add()
        domain.type = domain_type
        domain.value = domain_value
        for key, value in attributes:
            attr = domain.attribute.add()
            attr.key = key
            if isinstance(value, bool):
                attr.bool_value = value
            elif isinstance(value, int):
                attr.int_value = value
    
    with open(output_file, 'wb') as f:
        f.write(site_group_list.SerializeToString())

def main():
    # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•çš„ä¸Šä¸€çº§ç›®å½•
    script_dir = Path(__file__).parent
    parent_dir = script_dir.parent

    # è®¾ç½®è¾“å…¥è¾“å‡ºæ–‡ä»¶è·¯å¾„
    input_file = parent_dir / "site.dat"
    other_output = parent_dir / "site_cn_other.dat"
    binary_output = parent_dir / "site_cn_binary.dat"

    try:
        print("\nğŸš€ Starting domain extraction process...")
        print(f"ğŸ“‚ Input file: {input_file}")
        print(f"ğŸ“‚ Output files will be saved to: {parent_dir}")
        
        extract_and_split_domains(str(input_file), str(other_output), str(binary_output))
        print("\nâœ¨ Process completed successfully!")
        
    except Exception as e:
        print(f"\nâŒ Error: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()