# extract_cn_domains.py
import sys
import os
from google.protobuf.internal.decoder import _DecodeVarint32
from google.protobuf.internal.encoder import _EncodeVarint
import geosite_pb2
import time
from collections import Counter

def format_size(size):
    """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°æ˜¾ç¤º"""
    for unit in ['B', 'KB', 'MB', 'GB']:
        if size < 1024.0:
            return f"{size:.2f} {unit}"
        size /= 1024.0
    return f"{size:.2f} TB"

def analyze_dat(file_path):
    """åˆ†ædatæ–‡ä»¶çš„å†…å®¹"""
    print(f"\nğŸ“– Analyzing: {file_path}")
    print(f"ğŸ“Š File size: {format_size(os.path.getsize(file_path))}")
    
    try:
        with open(file_path, 'rb') as f:
            data = f.read()
            site_group_list = geosite_pb2.SiteGroupList()
            site_group_list.ParseFromString(data)
            
        stats = {
            'groups': len(site_group_list.site_group),
            'domains': 0,
            'types': Counter(),
            'attributes': Counter(),
            'tags': []
        }
        
        for group in site_group_list.site_group:
            stats['tags'].append(group.tag)
            stats['domains'] += len(group.domain)
            
            for domain in group.domain:
                stats['types'][geosite_pb2.Domain.Type.Name(domain.type)] += 1
                for attr in domain.attribute:
                    if attr.HasField('bool_value'):
                        stats['attributes'][f"{attr.key}(bool)"] += 1
                    elif attr.HasField('int_value'):
                        stats['attributes'][f"{attr.key}(int)"] += 1
        
        return stats, site_group_list
        
    except Exception as e:
        print(f"âŒ Error analyzing file: {e}")
        return None, None

def print_stats(stats):
    """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
    if not stats:
        return
        
    print("\nğŸ“Š File Statistics:")
    print(f"  â€¢ Groups: {stats['groups']}")
    print(f"  â€¢ Total domains: {stats['domains']}")
    
    print("\n  â€¢ Domain types distribution:")
    for type_name, count in stats['types'].most_common():
        print(f"    - {type_name}: {count} ({count/stats['domains']*100:.1f}%)")
    
    if stats['attributes']:
        print("\n  â€¢ Attributes distribution:")
        for attr_name, count in stats['attributes'].most_common():
            print(f"    - {attr_name}: {count}")
    
    print("\n  â€¢ Tags:")
    for tag in stats['tags']:
        print(f"    - {tag}")

def extract_cn_domains(input_file):
    """ä»site.datä¸­æå–cnå’Œapple-cnçš„åŸŸå"""
    start_time = time.time()
    
    # åˆ†æè¾“å…¥æ–‡ä»¶
    print("\nğŸ“Œ Analyzing input file...")
    input_stats, site_group_list = analyze_dat(input_file)
    if not input_stats:
        raise Exception("Failed to analyze input file")
    print_stats(input_stats)
    
    cn_domains = set()
    target_tags = {'cn', 'apple-cn'}
    domain_type_count = Counter()
    
    try:
        original_cn_count = 0
        for site_group in site_group_list.site_group:
            if site_group.tag.lower() in target_tags:
                print(f"\nğŸ·ï¸  Processing tag: {site_group.tag}")
                domain_count = 0
                original_cn_count += len(site_group.domain)
                
                for domain in site_group.domain:
                    domain_type = domain.type
                    domain_value = domain.value
                    type_str = geosite_pb2.Domain.Type.Name(domain_type)
                    domain_type_count[type_str] += 1
                    
                    attributes = [(attr.key, 
                                 attr.bool_value if attr.HasField('bool_value') 
                                 else attr.int_value if attr.HasField('int_value') 
                                 else None) 
                                for attr in domain.attribute]
                    
                    if domain_count < 5:  # åªæ˜¾ç¤ºå‰5ä¸ªåŸŸåä½œä¸ºç¤ºä¾‹
                        print(f"  ğŸ’  {type_str}: {domain_value} {attributes if attributes else ''}")
                    elif domain_count == 5:
                        print("  ... (more domains)")
                    domain_count += 1
                    
                    cn_domains.add((domain_type, domain_value, tuple(attributes)))
                print(f"  âœ… Found {domain_count} domains in {site_group.tag}")

    except Exception as e:
        print(f"âŒ Error processing domains: {e}")
        raise

    elapsed_time = time.time() - start_time
    print(f"\nâ±ï¸  Processing completed in {elapsed_time:.2f} seconds")
    print(f"\nğŸ“Š Extraction Statistics:")
    print(f"  â€¢ Original CN domains: {original_cn_count}")
    print(f"  â€¢ Unique domains after merge: {len(cn_domains)}")
    print(f"  â€¢ Domain types distribution:")
    for type_name, count in domain_type_count.most_common():
        print(f"    - {type_name}: {count} ({count/len(cn_domains)*100:.1f}%)")
    
    return cn_domains

def write_cn_dat(domains, output_file):
    """å°†åˆå¹¶åçš„åŸŸåå†™å…¥æ–°çš„site_cn.datæ–‡ä»¶"""
    start_time = time.time()
    print(f"\nğŸ’¾ Writing to: {output_file}")
    
    # åˆ›å»ºä¸€ä¸ªæ–°çš„SiteGroupList
    site_group_list = geosite_pb2.SiteGroupList()
    site_group = site_group_list.site_group.add()
    site_group.tag = "cn"
    
    for domain_type, domain_value, attributes in sorted(domains):
        domain = site_group.domain.add()
        domain.type = domain_type
        domain.value = domain_value
        for key, value in attributes:
            attr = domain.attribute.add()
            attr.key = key
            if isinstance(value, bool):
                attr.bool_value = value
            elif isinstance(value, int):
                attr.int_value = value

    # åºåˆ—åŒ–å¹¶å†™å…¥æ–‡ä»¶
    with open(output_file, 'wb') as f:
        f.write(site_group_list.SerializeToString())
    
    # éªŒè¯è¾“å‡ºæ–‡ä»¶
    print("\nğŸ“Œ Verifying output file...")
    output_stats, _ = analyze_dat(output_file)
    if output_stats:
        print_stats(output_stats)
    
    new_size = os.path.getsize(output_file)
    elapsed_time = time.time() - start_time
    print(f"\nâœ… Write completed in {elapsed_time:.2f} seconds")
    
    # æ–‡ä»¶å¤§å°æ¯”è¾ƒ
    original_size = os.path.getsize(sys.argv[1])
    print(f"\nğŸ’¾ Size comparison:")
    print(f"  â€¢ Original: {format_size(original_size)}")
    print(f"  â€¢ Extracted: {format_size(new_size)}")
    compression_ratio = (original_size - new_size) / original_size * 100
    print(f"  â€¢ Reduction: {compression_ratio:.1f}% ({format_size(original_size - new_size)})")

def main():
    if len(sys.argv) != 3:
        print("Usage: python extract_cn_domains.py <input_site.dat> <output_site_cn.dat>")
        sys.exit(1)

    input_file = sys.argv[1]
    output_file = sys.argv[2]

    try:
        print("\nğŸš€ Starting domain extraction process...")
        cn_domains = extract_cn_domains(input_file)
        write_cn_dat(cn_domains, output_file)
        print("\nâœ¨ Process completed successfully!")
        
    except Exception as e:
        print(f"\nâŒ Error: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()